{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcorneliusvh/semantic_chatbot/blob/master/Looker_%26_Gemini_Semantic_Chatbot_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83a718e7"
      },
      "source": [
        "# Building a Semantic Layer Chatbot: From Looker to LLM Agents\n",
        "\n",
        "This notebook walks through the core logic of the \"Looker + Gemini\" chatbot. We will strip away all the Streamlit frontend code (`app.py`, `pages/`) and focus purely on the backend logic.\n",
        "\n",
        "Our goal is to build a system that can:\n",
        "1.  **Connect to Looker** using its Python SDK.\n",
        "2.  **Understand the Looker data model (Explore)** by fetching its metadata.\n",
        "3.  **Build a LangChain \"Tool\"** that allows an LLM to query Looker.\n",
        "4.  **Create an \"Agent\"** that can use this tool to answer questions.\n",
        "5.  **Build a \"Router\"** to create a multi-agent system that can hand off tasks between a **Looker Agent** and a **Python Data-Analysis Agent**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Section 1: Setup and Credentials**\n",
        "\n",
        "First, we need to install the required libraries and set up our API keys.\n",
        "\n",
        "This system requires two sets of credentials:\n",
        "1.  **Google Gemini API Key**: For powering the LLMs.\n",
        "2.  **Looker SDK Credentials**: To allow the Python script to authenticate with your Looker instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5499048e",
        "outputId": "3fb231a3-7658-4d71-9ab9-b3830cdd1f33"
      },
      "source": [
        "# This file is a Python script formatted as a teaching notebook.\n",
        "# You can run it \"cell\" by \"cell\" in an IDE like VS Code (which supports\n",
        "# # %% cell dividers) or a standard Jupyter Notebook environment.\n",
        "\n",
        "# %%\n",
        "!pip install \"langchain>=0.2.0\" langchain-google-genai looker-sdk pandas langchain-community langchain-experimental duckduckgo-search"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain>=0.2.0 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: looker-sdk in /usr/local/lib/python3.12/dist-packages (25.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-experimental in /usr/local/lib/python3.12/dist-packages (0.3.4)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.12/dist-packages (8.1.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0) (6.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from looker-sdk) (4.15.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.12/dist-packages (from looker-sdk) (25.3.0)\n",
            "Requirement already satisfied: cattrs>=1.3 in /usr/local/lib/python3.12/dist-packages (from looker-sdk) (25.2.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.2.0) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.2.0) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain>=0.2.0) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain>=0.2.0) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain>=0.2.0) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain>=0.2.0) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.0) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain>=0.2.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain>=0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain>=0.2.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain>=0.2.0) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.2.0) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.2.0) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.2.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.2.0) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain>=0.2.0) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.2.0) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c721c8a"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import io\n",
        "from urllib.parse import urlencode\n",
        "\n",
        "# --- LangChain Core ---\n",
        "from langchain_core.tools import StructuredTool, tool\n",
        "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableBranch, RunnablePassthrough\n",
        "from langchain.output_parsers.pydantic import PydanticOutputParser\n",
        "from langchain import hub\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "from langchain_core.tools import render_text_description\n",
        "\n",
        "# --- LLM Imports ---\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# --- Pydantic Schemas ---\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Dict, Optional, Literal\n",
        "\n",
        "# --- Looker SDK ---\n",
        "import looker_sdk\n",
        "from looker_sdk import models40\n",
        "\n",
        "# --- Other Tools ---\n",
        "from langchain_community.tools import DuckDuckGoSearchRun"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "821e5af1"
      },
      "source": [
        "### **1.1. Set Up Your Credentials**\n",
        "\n",
        "We use `os.environ` to load credentials. In a real notebook, you might use `userdata.get()` (in Colab) or another secrets manager.\n",
        "\n",
        "**IMPORTANT:** Replace the placeholder values below with your actual credentials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0ecc2f2"
      },
      "source": [
        "# --- 1. SET UP YOUR CREDENTIALS ---\n",
        "# We use os.environ to load credentials.\n",
        "# In a real notebook, you might use `userdata.get()` (in Colab) or another secrets manager.\n",
        "#\n",
        "# !!!!!!!!!!!!!!!!!!\n",
        "# !! IMPORTANT:     !!\n",
        "# !! REPLACE THESE  !!\n",
        "# !! PLACEHOLDERS   !!\n",
        "# !!!!!!!!!!!!!!!!!!\n",
        "from google.colab import userdata\n",
        "# 1a. Google Gemini API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# 1b. Looker SDK Credentials\n",
        "# These are read by the looker_sdk.init40() function\n",
        "os.environ[\"LOOKERSDK_BASE_URL\"] = \"https://igmprinting.cloud.looker.com:19999\" # Must include :19999\n",
        "os.environ[\"LOOKERSDK_CLIENT_ID\"] = userdata.get('LOOKERSDK_CLIENT_ID')\n",
        "os.environ[\"LOOKERSDK_CLIENT_SECRET\"] = userdata.get('LOOKERSDK_CLIENT_SECRET')\n",
        "os.environ[\"LOOKERSDK_VERIFY_SSL\"] = \"true\"\n",
        "os.environ[\"LOOKERSDK_TIMEOUT\"] = \"120\"\n",
        "\n",
        "# --- 2. SET UP BROWSER URL (for Embeds) ---\n",
        "# This is the URL you use to access Looker in your browser (no :19999)\n",
        "LOOKER_BROWSER_URL = \"https://igmprinting.cloud.looker.com\"\n",
        "\n",
        "# --- 3. DEFINE MODEL AND EXPLORE ---\n",
        "# These must match the Looker Explore you want to query\n",
        "# We'll use the ones from the uploaded files\n",
        "MODEL_NAME = \"data_block_acs_bigquery\"\n",
        "EXPLORE_NAME = \"acs_census_data\""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e7db748"
      },
      "source": [
        "---\n",
        "\n",
        "## **Section 2: The Foundation - The Looker Semantic Layer**\n",
        "\n",
        "An LLM cannot guess your database schema or business logic. To make it \"semantically aware,\" we must provide it with **metadata**. This metadata, generated from your Looker model, is what \"ground\" the LLM, enabling it to map natural language (\"total population\") to the correct LookML field (`blockgroup.total_pop`).\n",
        "\n",
        "### **2.1. Fetching Looker Metadata (One-Time-Setup)**\n",
        "\n",
        "The first step is to run a script (like `01_fetch_metadata.py`) to connect to your Looker instance and pull the schema for your desired Explore. This generates a JSON file that the agent will use as its \"brain.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1f27ba0",
        "outputId": "6e81370b-fbdb-4e8e-9d5f-b3e160161c16"
      },
      "source": [
        "def fetch_explore_metadata(sdk: looker_sdk.sdk.api40.methods.Looker40SDK, model_name: str, explore_name: str, output_filename: str):\n",
        "    \"\"\"\n",
        "    Fetches all dimensions and measures for a given Looker Explore\n",
        "    and saves them to a JSON file.\n",
        "\n",
        "    This is based on 01_fetch_metadata.py\n",
        "    \"\"\"\n",
        "    print(f\"Fetching metadata for {model_name}::{explore_name}...\")\n",
        "    try:\n",
        "        # 1. Get the explore definition from the Looker SDK\n",
        "        explore = sdk.lookml_model_explore(\n",
        "            lookml_model_name=model_name,\n",
        "            explore_name=explore_name,\n",
        "            fields=\"fields\" # Request the 'fields' definition\n",
        "        )\n",
        "\n",
        "        fields_data = []\n",
        "\n",
        "        # 2. Parse dimensions\n",
        "        if explore.fields and explore.fields.dimensions:\n",
        "            for dim in explore.fields.dimensions:\n",
        "                fields_data.append({\n",
        "                    \"name\": dim.name,\n",
        "                    \"label\": dim.label_short or dim.label,\n",
        "                    \"description\": dim.description,\n",
        "                    \"type\": \"dimension\"\n",
        "                })\n",
        "\n",
        "        # 3. Parse measures\n",
        "        if explore.fields and explore.fields.measures:\n",
        "            for mea in explore.fields.measures:\n",
        "                fields_data.append({\n",
        "                    \"name\": mea.name,\n",
        "                    \"label\": mea.label_short or mea.label,\n",
        "                    \"description\": mea.description,\n",
        "                    \"type\": \"measure\"\n",
        "                })\n",
        "\n",
        "        # 4. Save to a file\n",
        "        with open(output_filename, \"w\") as f:\n",
        "            json.dump(fields_data, f, indent=2)\n",
        "\n",
        "        print(f\"Successfully fetched {len(fields_data)} fields.\")\n",
        "        print(f\"Metadata saved to {output_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching explore: {e}\")\n",
        "\n",
        "# --- Initialize SDK and Run Metadata Fetch ---\n",
        "try:\n",
        "    # Use environment variables set in the previous cell\n",
        "    sdk = looker_sdk.init40()\n",
        "\n",
        "    # We'll name our file \"acs_census_metadata.json\"\n",
        "    METADATA_FILE = \"acs_census_metadata.json\"\n",
        "\n",
        "    fetch_explore_metadata(sdk, MODEL_NAME, EXPLORE_NAME, METADATA_FILE)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Failed to initialize Looker SDK or fetch metadata. Check credentials. Error: {e}\")\n",
        "    # In a real scenario, you'd stop here. For the notebook, we'll assume the file exists.\n",
        "\n",
        "# Clean up the SDK connection\n",
        "if 'sdk' in locals():\n",
        "    # sdk.auth.logout() # This can sometimes hang, optional\n",
        "    pass"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching metadata for data_block_acs_bigquery::acs_census_data...\n",
            "Successfully fetched 360 fields.\n",
            "Metadata saved to acs_census_metadata.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d8573a0"
      },
      "source": [
        "### **2.2. Building the Looker Tool**\n",
        "\n",
        "Now we build the Python function that will become our LangChain `StructuredTool`. This function (based on `tools/looker_tool.py`) is the core of the Looker connection.\n",
        "\n",
        "It will:\n",
        "1.  **Load** the metadata JSON we just created.\n",
        "2.  **Define** a Pydantic schema (`LookerQueryInput`) to force the LLM to provide valid query parameters.\n",
        "3.  **Define** the main query function (`_run_looker_query`) that authenticates, builds a `WriteQuery`, runs it, and formats an embed URL.\n",
        "4.  **Wrap** this function in a `StructuredTool` for the agent to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a42253c8"
      },
      "source": [
        "# --- 1. Helper function to load metadata ---\n",
        "def _get_explore_metadata(metadata_file: str) -> str:\n",
        "    \"\"\"Loads the explore metadata JSON file and returns it as a string.\"\"\"\n",
        "    try:\n",
        "        with open(metadata_file) as f:\n",
        "            # We dump it into a string so it can be easily injected into the prompt\n",
        "            return json.dumps(json.load(f))\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Fatal Error: {metadata_file} not found. Please run the metadata fetch cell.\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {metadata_file}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Load the metadata into a global variable for the tool prompt\n",
        "EXPLORE_METADATA = _get_explore_metadata(METADATA_FILE)\n",
        "if not EXPLORE_METADATA:\n",
        "    print(\"Warning: Metadata is empty. The Looker agent will not know what fields to query.\")\n",
        "\n",
        "# --- 2. Pydantic Schema for LLM Input ---\n",
        "class LookerQueryInput(BaseModel):\n",
        "    \"\"\"Input schema for running a Looker query.\"\"\"\n",
        "    fields: List[str] = Field(description=\"List of dimensions and measures, e.g., ['state.state_name', 'blockgroup.total_pop']\")\n",
        "    filters: Optional[Dict[str, str]] = Field(description=\"Dictionary of filters, e.g., {'state.state_name': 'California'}\", default={})\n",
        "    sorts: Optional[List[str]] = Field(description=\"List of fields to sort by, e.g., ['blockgroup.total_pop desc']\", default=[])\n",
        "    limit: Optional[str] = Field(description=\"Row limit for the query\", default=\"500\")\n",
        "    vis_config_string: str = Field(\n",
        "        description=\"A valid Looker vis_config JSON object, as a string. Use a simple 'table' viz if unsure.\",\n",
        "        default='{\"type\": \"table\"}'\n",
        "    )\n",
        "\n",
        "# --- 3. Core Looker Query Function ---\n",
        "def _run_looker_query(\n",
        "    fields: List[str],\n",
        "    filters: Optional[Dict[str, str]] = {},\n",
        "    sorts: Optional[List[str]] = [],\n",
        "    limit: Optional[str] = \"500\",\n",
        "    vis_config_string: str = '{\"type\": \"table\"}'\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Runs a dynamic query to get data AND builds a full Expanded URL for embedding.\n",
        "    This is the primary tool for all US Census data questions.\n",
        "\n",
        "    (Based on tools/looker_tool.py)\n",
        "    \"\"\"\n",
        "    if not fields:\n",
        "        return json.dumps({\"error\": \"You must provide at least one field.\"})\n",
        "\n",
        "    sdk = None\n",
        "    try:\n",
        "        # 1. Initialize the SDK (it reads from os.environ)\n",
        "        sdk = looker_sdk.init40()\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Looker SDK not initialized. Check credentials. {e}\"})\n",
        "\n",
        "    try:\n",
        "        # 2. Create the query payload\n",
        "        vis_config_dict = json.loads(vis_config_string) # Parse string to dict\n",
        "\n",
        "        query_payload = models40.WriteQuery(\n",
        "            model=MODEL_NAME,\n",
        "            view=EXPLORE_NAME,\n",
        "            fields=fields,\n",
        "            filters=filters,\n",
        "            sorts=sorts,\n",
        "            limit=str(limit),\n",
        "            vis_config=vis_config_dict\n",
        "        )\n",
        "\n",
        "        # 3. Run the query inline to get the data\n",
        "        print(f\"--- Running Looker Inline Query --- \\n{query_payload}\")\n",
        "        data_result = sdk.run_inline_query(\n",
        "            result_format=\"json\",\n",
        "            body=query_payload\n",
        "        )\n",
        "        print(\"--- Data Query Successful ---\")\n",
        "\n",
        "        # 4. Build the Expanded URL parameters\n",
        "        url_params = {}\n",
        "        url_params['fields'] = \",\".join(fields)\n",
        "        url_params['sorts'] = \",\".join(sorts)\n",
        "        url_params['limit'] = str(limit)\n",
        "        url_params['vis_config'] = vis_config_string\n",
        "        url_params['toggle'] = 'vis' # Use the 'vis' tab\n",
        "\n",
        "        filter_params = {}\n",
        "        for key, value in filters.items():\n",
        "            filter_params[f\"f[{key}]\"] = value\n",
        "\n",
        "        url_params.update(filter_params)\n",
        "        query_string = urlencode(url_params)\n",
        "\n",
        "        # 5. Build the final Embed URL\n",
        "        viz_url = f\"{LOOKER_BROWSER_URL}/embed/explore/{MODEL_NAME}/{EXPLORE_NAME}?{query_string}\"\n",
        "        print(f\"--- Expanded Embed URL Created: {viz_url} ---\")\n",
        "\n",
        "        # 6. Save the data to cache (for the Python agent)\n",
        "        # We'll use the cache_tool functions from the original repo\n",
        "        try:\n",
        "            df = pd.read_json(io.StringIO(data_result))\n",
        "            # Call the cache function directly\n",
        "            cache_summary = save_data_to_cache.func(df, \"data.csv\")\n",
        "            print(f\"--- {cache_summary} ---\")\n",
        "            data_summary = f\"Successfully queried and saved {len(df)} rows to data.csv.\"\n",
        "\n",
        "            # --- NEW: Add data preview and stats for the agent ---\n",
        "            # This is critical for the agent's \"Insights\" step\n",
        "            data_preview = df.head().to_json(orient='records')\n",
        "            data_stats = df.describe().to_json()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"--- Failed to save to cache --- \\n{e}\")\n",
        "            return json.dumps({\"error\": f\"Error saving data to cache: {e}\"})\n",
        "\n",
        "        # 7. Return a summary, URL, preview, and stats back to the agent\n",
        "        final_output = {\n",
        "            \"summary\": data_summary,\n",
        "            \"viz_url\": viz_url,\n",
        "            \"data_preview\": data_preview,\n",
        "            \"data_stats\": data_stats\n",
        "        }\n",
        "        return json.dumps(final_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- Query Failed --- \\n{e}\")\n",
        "        return json.dumps({\"error\": f\"Error running Looker query: {e}\"})\n",
        "    finally:\n",
        "        if sdk:\n",
        "            # sdk.auth.logout() # Optional\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aef8acc"
      },
      "source": [
        "### **2.3. Defining the Caching and Knowledge Tools**\n",
        "\n",
        "The Looker agent needs two helper tools:\n",
        "1.  `save_data_to_cache`: To save the query results.\n",
        "2.  `get_census_data_definition`: To answer questions about what fields mean.\n",
        "\n",
        "We also define `load_df_from_cache` for the Python agent later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24291510"
      },
      "source": [
        "# --- 1. Caching Tools ---\n",
        "# (From tools/cache_tool.py)\n",
        "# We need to define these so _run_looker_query can call them.\n",
        "\n",
        "@tool\n",
        "def save_data_to_cache(dataf: pd.DataFrame, file_path: str = \"data.csv\") -> str:\n",
        "    \"\"\"\n",
        "    Saves a pandas DataFrame to a CSV file.\n",
        "    This notebook uses 'data.csv' as the default.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dataf.to_csv(file_path, index=False)\n",
        "        return f\"Data saved to {file_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error saving data: {e}\"\n",
        "\n",
        "@tool\n",
        "def load_df_from_cache(file_path: str = \"data.csv\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads data from a CSV file into a pandas DataFrame.\n",
        "    Returns None if the file is not found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Cache file not found: {file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading cache: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- 2. Knowledge Tool ---\n",
        "# (From tools/knowledge_tool.py)\n",
        "# This is another tool the agent will use.\n",
        "\n",
        "class TermInput(BaseModel):\n",
        "    term: str = Field(description=\"The census term to define, e.g., 'poverty line' or 'median income'.\")\n",
        "\n",
        "@tool(args_schema=TermInput)\n",
        "def get_census_data_definition(term: str) -> str:\n",
        "    \"\"\"\n",
        "    Looks up the definition for a specific US Census term from the metadata file.\n",
        "    Use this to answer questions like 'What is the poverty line?' or 'Define median income'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(METADATA_FILE, 'r') as f:\n",
        "            # The file from the repo is a list of dicts.\n",
        "            metadata = json.load(f)\n",
        "\n",
        "        search_term = term.lower().strip()\n",
        "\n",
        "        for field in metadata:\n",
        "            # Check 'name', 'label', and 'description' for the term\n",
        "            if (search_term in field.get('name', '').lower() or\n",
        "                search_term in field.get('label', '').lower() or\n",
        "                search_term in field.get('description', '').lower()):\n",
        "                return f\"Definition for '{field.get('name')}' ({field.get('label')}): {field.get('description')}\"\n",
        "\n",
        "        return f\"Sorry, I could not find a definition for the term '{term}'.\"\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: The census metadata file ({METADATA_FILE}) was not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error reading census metadata: {e}\"\n",
        "\n",
        "# --- 3. Define the Final Looker Tool Wrapper ---\n",
        "# This tool's description is CRITICAL. It includes the entire metadata schema,\n",
        "# \"grounding\" the LLM on what fields are available.\n",
        "# (This logic is from app.py's `create_looker_agent_chain`)\n",
        "\n",
        "looker_data_tool = StructuredTool.from_function(\n",
        "    func=_run_looker_query, # Use our main function\n",
        "    name=\"LookerDataQuery\",\n",
        "    description=(\n",
        "        \"Use this tool as the **primary source** for ANY questions about US population or census demographics. \"\n",
        "        \"This includes nationwide totals (e.g., 'What is the total population of the US?') as well as specific breakdowns \"\n",
        "        \"by geography (e.g., 'What is the population in California?', 'List median income by county in Texas').\\n\\n\"\n",
        "\n",
        "        \"**CRITICAL QUERY-BUILDING INSTRUCTIONS:**\\n\"\n",
        "        \"1.  To get a total, aggregated value (like 'total population'), you **MUST** use the 'measure' field (e.g., `blockgroup.total_pop`).\\n\"\n",
        "        \"2.  For a general nationwide 'total population', you MUST use the measure `blockgroup.total_pop` and apply no filters.\\n\"\n",
        "        \"3.  To group data by a category (like 'by state'), you must add that 'dimension' (e.g., `state.state_name`) to the `fields` list along with the measure.\\n\"\n",
        "        \"4.  You MUST also generate a `vis_config_string`. This is a JSON object *as a string*.\\n\"\n",
        "        \"   - For single numbers (like total population), use: `'{\\\"type\\\": \\\"single_value\\\"}'`\\n\"\n",
        "        \"   - For tables (data grouped by state), use: `'{\\\"type\\\": \\\"table\\\"}'`\\n\"\n",
        "        \"   - For maps (data by state), use: `'{\\\"type\\\": \\\"looker_map\\\", \\\"map_field_name\\\": \\\"state.state_name\\\"}'`\\n\"\n",
        "        \"   - For bar charts (pop by state), use: `'{\\\"type\\\": \\\"looker_bar\\\", \\\"stacking\\\": \\\"normal\\\"}'`\\n\"\n",
        "        \"   - If unsure, default to: `'{\\\"type\\\": \\\"table\\\"}'`\\n\\n\"\n",
        "\n",
        "        f\"Here is the complete schema of available fields: {EXPLORE_METADATA}\"\n",
        "    ),\n",
        "    args_schema=LookerQueryInput\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc459de4"
      },
      "source": [
        "---\n",
        "\n",
        "## **Section 3: The LLM Brain - A Simple Looker Agent**\n",
        "\n",
        "Now that we have our `looker_data_tool` and `get_census_data_definition` tool, we can build our first agent. This simple agent will *only* have access to these two tools. This is a great way to test the Looker connection in isolation.\n",
        "\n",
        "This section is based on `02_test_looker_agent.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "529b2375",
        "outputId": "ef0e5c3c-5cc7-414a-e9b6-9541428c691b"
      },
      "source": [
        "# --- 1. Initialize the LLMs ---\n",
        "# We use two models:\n",
        "# - Pro: For heavy reasoning (Python, General Search)\n",
        "# - Flash: For fast, structured tasks (Looker, Routing)\n",
        "# (From app.py)\n",
        "\n",
        "try:\n",
        "    llm_pro = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-pro\", # Use a powerful model for reasoning\n",
        "        google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
        "        temperature=0,\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "\n",
        "    llm_flash = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\", # Use a fast model for structured output\n",
        "        google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
        "        temperature=0,\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "\n",
        "    print(\"LLMs initialized (Pro and Flash).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing LLMs. Check GOOGLE_API_KEY. Error: {e}\")\n",
        "    # This is a critical step, so we'll raise an error to stop the notebook\n",
        "    raise e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLMs initialized (Pro and Flash).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "497dad25"
      },
      "source": [
        "### **3.1. Build the Simple Looker Agent**\n",
        "\n",
        "This is the prompt that tells the agent *how* to behave. Note the \"ANALYST STRATEGY\" and \"FINAL ANSWER\" sections, which are custom instructions to improve the agent's output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "119d664a"
      },
      "source": [
        "LOOKER_AGENT_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert assistant for US Census data. You have two tools:\n",
        "1.  `LookerDataQuery`: To get data and visualizations.\n",
        "2.  `get_census_data_definition`: To define terms.\n",
        "\n",
        "**ANALYST STRATEGY:**\n",
        "-   You are a senior data analyst. Your goal is to answer the user's question with the *most relevant* data.\n",
        "-   **If the user asks a strategic question (e.g., \"where should I open a bookstore?\"), DO NOT just query `blockgroup.total_pop`.**\n",
        "-   Instead, THINK about what data implies a good market. For a bookstore, good fields would be `blockgroup.bachelors_degree`, `blockgroup.masters_degree`, or `blockgroup.median_income_dim`.\n",
        "-   Select fields that *actually* answer the user's strategic question.\n",
        "\n",
        "**STRATEGY FOR `LookerDataQuery`:**\n",
        "-   You MUST provide a `vis_config_string` (a JSON string).\n",
        "-   **CHART PREFERENCE:** Prefer `'{{\\\"type\\\": \\\"looker_column\\\"}}'` or `'{{\\\"type\\\": \\\"looker_bar\\\"}}'` for most queries that compare values.\n",
        "-   Use `'{{\\\"type\\\": \\\"single_value\\\"}}'` for single-number answers.\n",
        "\n",
        "**STRATEGY FOR FINAL ANSWER:**\n",
        "-   Your tool will return a JSON object with: \"summary\", \"viz_url\", \"data_preview\", and \"data_stats\".\n",
        "-   Your \"Final Answer\" to the user must be a 1-2 paragraph response, formatted in MARKDOWN with two headings: '### Summary' and '### Insights'.\n",
        "-   Under '### Summary', describe the data that was retrieved.\n",
        "-   Under '### Insights', use the \"data_stats\" (for min/max/mean) and \"data_preview\" (for string examples) to provide a brief, *specific* analysis.\n",
        "-   **IMPORTANT**: Include the \"viz_url\" in your final answer so the user can see it.\n",
        "\n",
        "Here are the tools you must use:\n",
        "{tools}\n",
        "\n",
        "Here are the names of your tools: {tool_names}\n",
        "\n",
        "Use the following format for your thoughts and actions.\n",
        "(You MUST use this format. Do not just output the final answer.)\n",
        "\n",
        "Thought:\n",
        "(Your reasoning and plan)\n",
        "Action:\n",
        "```json\n",
        "{{\n",
        "  \"action\": \"Your chosen tool\",\n",
        "  \"action_input\": {{\"parameter\": \"value\"}}\n",
        "}}\n",
        "```\n",
        "Observation:\n",
        "(The tool's JSON output)\n",
        "Thought:\n",
        "(Your analysis of the tool's output)\n",
        "Action:\n",
        "```json\n",
        "{{\n",
        "  \"action\": \"Final Answer\",\n",
        "  \"action_input\": \"### Summary\\n\\n(Your summary here)\\n\\n### Insights\\n\\n(Your insights here)\\n\\nHere is the link to the visualization: [Looker Viz](viz_url_here)\"\n",
        "}}\n",
        "```\n",
        "\n",
        "CHAT HISTORY:\n",
        "{chat_history}\n",
        "\n",
        "USER INPUT: {input}\n",
        "\n",
        "Begin!\n",
        "Thought:\n",
        "{agent_scratchpad}\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29825f5e"
      },
      "source": [
        "### **3.2. Test the Simple Looker Agent**\n",
        "\n",
        "Let's run the agent we just created.\n",
        "\n",
        "**Note:** This will make a **LIVE API CALL** to Looker using the credentials you provided in Section 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3361453"
      },
      "source": [
        "def create_simple_looker_agent():\n",
        "    \"\"\"Creates an AgentExecutor that can only use the Looker and Knowledge tools.\"\"\"\n",
        "\n",
        "    tools = [looker_data_tool, get_census_data_definition]\n",
        "\n",
        "    agent_prompt = PromptTemplate(\n",
        "        template=LOOKER_AGENT_PROMPT_TEMPLATE,\n",
        "        input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
        "        partial_variables={\n",
        "            \"tools\": render_text_description(tools),\n",
        "            \"tool_names\": \", \".join([t.name for t in tools])\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # We use the fast 'flash' model for the Looker agent\n",
        "    agent = create_structured_chat_agent(llm_flash, tools, agent_prompt)\n",
        "\n",
        "    agent_executor = AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        verbose=True, # Set to True to see the agent's \"thoughts\"\n",
        "        handle_parsing_errors=True,\n",
        "        max_iterations=8\n",
        "    ).with_config({\"run_name\": \"LookerAgent\"})\n",
        "\n",
        "    return agent_executor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59a15b46",
        "outputId": "105de74e-8f6c-4320-bff5-d05b15fa4a56"
      },
      "source": [
        "simple_looker_agent = create_simple_looker_agent()\n",
        "\n",
        "# --- 2. Test 1: A definition question ---\n",
        "print(\"--- TEST 1: Definition Query ---\")\n",
        "response_1 = simple_looker_agent.invoke({\n",
        "    \"input\": \"What does 'blockgroup.total_pop' mean?\",\n",
        "    \"chat_history\": []\n",
        "})\n",
        "print(f\"--- FINAL AGENT OUTPUT 1 ---\\n{response_1['output']}\")\n",
        "\n",
        "# %%\n",
        "# --- 3. Test 2: A data question ---\n",
        "print(\"\\n\\n--- TEST 2: Data Query ---\")\n",
        "response_2 = simple_looker_agent.invoke({\n",
        "    \"input\": \"What is the total population of the US?\",\n",
        "    \"chat_history\": []\n",
        "})\n",
        "print(f\"--- FINAL AGENT OUTPUT 2 ---\\n{response_2['output']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TEST 1: Definition Query ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LookerAgent chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe user is asking for the definition of a specific census term, 'blockgroup.total_pop'. I should use the `get_census_data_definition` tool to retrieve this information.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"get_census_data_definition\",\n",
            "  \"action_input\": {\n",
            "    \"term\": \"blockgroup.total_pop\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3mDefinition for 'blockgroup.total_pop_dim' (Total Pop Dim): Total Population. The total number of all people living in a given geographic area.  This is a very useful catch-all denominator when calculating rates.\u001b[0m\u001b[32;1m\u001b[1;3mThe tool returned the definition for 'blockgroup.total_pop_dim', which is \"Total Population. The total number of all people living in a given geographic area. This is a very useful catch-all denominator when calculating rates.\" This directly answers the user's question. I will now format this into the final answer.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"### Summary\\n\\nThe term 'blockgroup.total_pop' refers to the **Total Population** within a given geographic area. \\n\\n### Insights\\n\\nThis measure represents the total number of all people living in a specific block group. It is a fundamental demographic statistic often used as a denominator when calculating various rates or proportions within that geographic area.\\n\\nHere is the link to the visualization: [Looker Viz](No visualization was generated for this definition query.)\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "--- FINAL AGENT OUTPUT 1 ---\n",
            "### Summary\n",
            "\n",
            "The term 'blockgroup.total_pop' refers to the **Total Population** within a given geographic area. \n",
            "\n",
            "### Insights\n",
            "\n",
            "This measure represents the total number of all people living in a specific block group. It is a fundamental demographic statistic often used as a denominator when calculating various rates or proportions within that geographic area.\n",
            "\n",
            "Here is the link to the visualization: [Looker Viz](No visualization was generated for this definition query.)\n",
            "\n",
            "\n",
            "--- TEST 2: Data Query ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LookerAgent chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe user is asking for the total population of the US. I need to use the `LookerDataQuery` tool to get this information. The relevant field for total population is `blockgroup.total_pop`. Since the user is asking for the total US population, I will not apply any filters and will use a `single_value` visualization type.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"LookerDataQuery\",\n",
            "  \"action_input\": {\n",
            "    \"fields\": [\"blockgroup.total_pop\"],\n",
            "    \"vis_config_string\": \"{\\\"type\\\": \\\"single_value\\\"}\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m--- Running Looker Inline Query --- \n",
            "WriteQuery(model='data_block_acs_bigquery', view='acs_census_data', fields=['blockgroup.total_pop'], pivots=None, fill_fields=None, filters={}, filter_expression=None, sorts=[], limit='500', column_limit=None, total=None, row_total=None, subtotals=None, vis_config={'type': 'single_value'}, filter_config=None, visible_ui_sections=None, dynamic_fields=None, client_id=None, query_timezone=None)\n",
            "--- Data Query Successful ---\n",
            "--- Expanded Embed URL Created: https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis ---\n",
            "--- Data saved to data.csv ---\n",
            "\u001b[36;1m\u001b[1;3m{\"summary\": \"Successfully queried and saved 1 rows to data.csv.\", \"viz_url\": \"https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis\", \"data_preview\": \"[{\\\"blockgroup.total_pop\\\":326289971}]\", \"data_stats\": \"{\\\"blockgroup.total_pop\\\":{\\\"count\\\":1.0,\\\"mean\\\":326289971.0,\\\"std\\\":null,\\\"min\\\":326289971.0,\\\"25%\\\":326289971.0,\\\"50%\\\":326289971.0,\\\"75%\\\":326289971.0,\\\"max\\\":326289971.0}}\"}\u001b[0m\u001b[32;1m\u001b[1;3mThe tool successfully returned the total population of the US. I can now formulate the final answer using the provided summary, viz_url, and data_stats.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"### Summary\\n\\nThe query retrieved the total population for the United States.\\n\\n### Insights\\n\\nThe total population of the US is 326,289,971. This is a single aggregated value representing the entire country.\\n\\nHere is the link to the visualization: [Looker Viz](https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis)\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "--- FINAL AGENT OUTPUT 2 ---\n",
            "### Summary\n",
            "\n",
            "The query retrieved the total population for the United States.\n",
            "\n",
            "### Insights\n",
            "\n",
            "The total population of the US is 326,289,971. This is a single aggregated value representing the entire country.\n",
            "\n",
            "Here is the link to the visualization: [Looker Viz](https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f80ac139",
        "outputId": "9d6e734e-43aa-4a8d-f5c5-0f5cc4e3cf19"
      },
      "source": [
        "# --- 3. Test 2: A data question ---\n",
        "print(\"\\n\\n--- TEST 2: Data Query ---\")\n",
        "response_2 = simple_looker_agent.invoke({\n",
        "    \"input\": \"What is the total population of the US?\",\n",
        "    \"chat_history\": []\n",
        "})\n",
        "print(f\"--- FINAL AGENT OUTPUT 2 ---\\n{response_2['output']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- TEST 2: Data Query ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LookerAgent chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe user is asking for the total population of the US. I need to use the `LookerDataQuery` tool to get this information. The relevant field for total population is `blockgroup.total_pop`. Since the user is asking for the total US population, I will not apply any filters and will use a `single_value` visualization.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"LookerDataQuery\",\n",
            "  \"action_input\": {\n",
            "    \"fields\": [\"blockgroup.total_pop\"],\n",
            "    \"vis_config_string\": \"{\\\"type\\\": \\\"single_value\\\"}\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m--- Running Looker Inline Query --- \n",
            "WriteQuery(model='data_block_acs_bigquery', view='acs_census_data', fields=['blockgroup.total_pop'], pivots=None, fill_fields=None, filters={}, filter_expression=None, sorts=[], limit='500', column_limit=None, total=None, row_total=None, subtotals=None, vis_config={'type': 'single_value'}, filter_config=None, visible_ui_sections=None, dynamic_fields=None, client_id=None, query_timezone=None)\n",
            "--- Data Query Successful ---\n",
            "--- Expanded Embed URL Created: https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis ---\n",
            "--- Data saved to data.csv ---\n",
            "\u001b[36;1m\u001b[1;3m{\"summary\": \"Successfully queried and saved 1 rows to data.csv.\", \"viz_url\": \"https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis\", \"data_preview\": \"[{\\\"blockgroup.total_pop\\\":326289971}]\", \"data_stats\": \"{\\\"blockgroup.total_pop\\\":{\\\"count\\\":1.0,\\\"mean\\\":326289971.0,\\\"std\\\":null,\\\"min\\\":326289971.0,\\\"25%\\\":326289971.0,\\\"50%\\\":326289971.0,\\\"75%\\\":326289971.0,\\\"max\\\":326289971.0}}\"}\u001b[0m\u001b[32;1m\u001b[1;3mThe tool successfully returned the total population of the US. I can now formulate the final answer using the provided summary, viz_url, data_preview, and data_stats.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"### Summary\\n\\nThe query retrieved the total population of the United States.\\n\\n### Insights\\n\\nThe total population of the US is 326,289,971. This is a single aggregated value representing the entire country.\\n\\nHere is the link to the visualization: [Looker Viz](https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis)\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "--- FINAL AGENT OUTPUT 2 ---\n",
            "### Summary\n",
            "\n",
            "The query retrieved the total population of the United States.\n",
            "\n",
            "### Insights\n",
            "\n",
            "The total population of the US is 326,289,971. This is a single aggregated value representing the entire country.\n",
            "\n",
            "Here is the link to the visualization: [Looker Viz](https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=blockgroup.total_pop&sorts=&limit=500&vis_config=%7B%22type%22%3A+%22single_value%22%7D&toggle=vis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1845430"
      },
      "source": [
        "---\n",
        "\n",
        "## **Section 4: Building the Multi-Agent System**\n",
        "\n",
        "The simple agent is great, but it has a problem. What if the user asks an analysis question, like \"What's the *average* population?\" or \"Compare the population of California and Texas.\" The Looker agent isn't trained for that.\n",
        "\n",
        "To solve this, we create a **multi-agent system** (from `app.py`):\n",
        "1.  **Router:** A fast LLM (`llm_flash`) that classifies the user's query and routes it to the correct agent.\n",
        "2.  **Looker Agent:** The agent we just built, which is responsible for *data retrieval*.\n",
        "3.  **Python Agent:** A *new* agent (`llm_pro`) that is responsible for *data analysis*. Its only tool is a Python REPL that can read the `data.csv` file saved by the Looker agent.\n",
        "4.  **General Agent:** A fallback agent for small talk and web searches.\n",
        "\n",
        "### **4.1. The Router**\n",
        "\n",
        "This chain doesn't answer the question; it just classifies it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad4085b",
        "outputId": "030fe778-dd13-4cb0-e0b8-e1c3916d296b"
      },
      "source": [
        "# --- 1. Pydantic Model for Routing ---\n",
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Classifies the user's query to the appropriate agent.\"\"\"\n",
        "    destination: Literal[\"looker\", \"python_agent\", \"general\"] = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"The agent to route the query to. \"\n",
        "            \"'looker' for data retrieval/visualization about US census data (e.g., 'what is the population...'). \"\n",
        "            \"'python_agent' for analysis, math, or manipulation on *already cached* data (e.g., 'what is the average...', 'compare X and Y'). \"\n",
        "            \"'general' for conversation, definitions, web searches, or anything else.\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "# --- 2. Router Prompt ---\n",
        "router_prompt_template = \"\"\"\n",
        "You are an expert dispatcher routing user queries to the correct agent.\n",
        "Based on the user's query and chat history, you must classify it into one of the following destinations.\n",
        "Your response must be a JSON object matching the 'RouteQuery' Pydantic schema.\n",
        "\n",
        "{schema}\n",
        "\n",
        "CHAT HISTORY:\n",
        "{chat_history}\n",
        "\n",
        "USER QUERY:\n",
        "{input}\n",
        "\n",
        "CLASSIFICATION:\n",
        "\"\"\"\n",
        "\n",
        "# --- 3. Router Chain ---\n",
        "parser = PydanticOutputParser(pydantic_object=RouteQuery)\n",
        "\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_prompt_template,\n",
        "    input_variables=[\"input\", \"chat_history\"],\n",
        "    partial_variables={\"schema\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "# Use the fast model for the router\n",
        "router = router_prompt | llm_flash | parser\n",
        "\n",
        "# --- 4. Test the Router ---\n",
        "print(\"--- Testing Router ---\")\n",
        "query_1 = \"What is the population by state?\"\n",
        "route_1 = router.invoke({\"input\": query_1, \"chat_history\": []})\n",
        "print(f\"Query: '{query_1}' -> Route: {route_1.destination}\")\n",
        "\n",
        "query_2 = \"What is the average population from that data?\"\n",
        "# We simulate chat history to give context\n",
        "history_2 = [\n",
        "    HumanMessage(content=query_1),\n",
        "    AIMessage(content=\"I have retrieved the population by state and saved it to data.csv.\")\n",
        "]\n",
        "route_2 = router.invoke({\"input\": query_2, \"chat_history\": history_2})\n",
        "print(f\"Query: '{query_2}' -> Route: {route_2.destination}\")\n",
        "\n",
        "query_3 = \"Hello, how are you?\"\n",
        "route_3 = router.invoke({\"input\": query_3, \"chat_history\": []})\n",
        "print(f\"Query: '{query_3}' -> Route: {route_3.destination}\")\n",
        "\n",
        "query_4 = \"What's the weather today?\"\n",
        "route_4 = router.invoke({\"input\": query_4, \"chat_history\": []})\n",
        "print(f\"Query: '{query_4}' -> Route: {route_4.destination}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Router ---\n",
            "Query: 'What is the population by state?' -> Route: looker\n",
            "Query: 'What is the average population from that data?' -> Route: python_agent\n",
            "Query: 'Hello, how are you?' -> Route: general\n",
            "Query: 'What's the weather today?' -> Route: general\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "003f338e"
      },
      "source": [
        "### **4.2. The Python Agent (Data Analyst)**\n",
        "\n",
        "This agent is an expert in Python and pandas. Its prompt *commands* it to load `data.csv` first, then perform analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b25d508"
      },
      "source": [
        "PYTHON_AGENT_PROMPT_TEMPLATE = \"\"\"\n",
        "You are an expert Python data analyst. You have access to a Python REPL tool.\n",
        "Your primary task is to answer the user's question by analyzing a pandas DataFrame named `df`.\n",
        "\n",
        "**CRITICAL CONTEXT:**\n",
        "- A file named `data.csv` exists in the local directory.\n",
        "- Your **FIRST ACTION** must *always* be to load this file into a pandas DataFrame named `df`.\n",
        "  Example: `import pandas as pd\\ndf = pd.read_csv('data.csv')`\n",
        "- After loading, your second action should *always* be to inspect the columns: `print(df.columns)`\n",
        "- **DO NOT** assume `df` is already loaded. You must load it *every time*.\n",
        "- The pandas library is available as `pd`.\n",
        "\n",
        "**STRATEGY FOR FINAL ANSWER:**\n",
        "- Your final answer should be conversational, explaining what you found.\n",
        "- Do not just output the raw number. Explain what it means.\n",
        "\n",
        "Here are the tools you must use:\n",
        "{tools}\n",
        "\n",
        "Here are the names of your tools: {tool_names}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Thought:\n",
        "(Your plan: load data, inspect, then analyze)\n",
        "Action:\n",
        "```json\n",
        "{{\n",
        "  \"action\": \"Python_REPL\",\n",
        "  \"action_input\": \"import pandas as pd\\ndf = pd.read_csv('data.csv')\\nprint(df.columns)\"\n",
        "}}\n",
        "```\n",
        "Observation:\n",
        "(The tool's output, e.g., \"Index(['state.state_name', ...])\")\n",
        "Thought:\n",
        "(Your plan to analyze the correct columns)\n",
        "Action:\n",
        "```json\n",
        "{{\n",
        "  \"action\": \"Python_REPL\",\n",
        "  \"action_input\": \"result = df['blockgroup.total_pop'].mean()\\nprint(result)\"\n",
        "}}\n",
        "```\n",
        "Observation:\n",
        "(The tool's output, e.g., \"12345.67\")\n",
        "Thought:\n",
        "(Your plan to formulate a final, conversational answer)\n",
        "Action:\n",
        "```json\n",
        "{{\n",
        "  \"action\": \"Final Answer\",\n",
        "  \"action_input\": \"I've finished the analysis. The average population from the data is 12,345.67.\"\n",
        "}}\n",
        "```\n",
        "\n",
        "CHAT HISTORY:\n",
        "{chat_history}\n",
        "\n",
        "USER INPUT: {input}\n",
        "\n",
        "Begin!\n",
        "Thought:\n",
        "{agent_scratchpad}\n",
        "\"\"\"\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac7875ee"
      },
      "source": [
        "### **4.3. The General Agent (Fallback)**\n",
        "\n",
        "This agent handles everything else, including general knowledge and web searches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b07d7eb"
      },
      "source": [
        "# %%\n",
        "# --- 1. General Agent Prompt ---\n",
        "GENERAL_AGENT_PROMPT_TEMPLATE = \"\"\"\n",
        "You are a helpful assistant.\n",
        "Your goal is to provide helpful, conversational answers to the user's question.\n",
        "You have tools for looking up specific US Census definitions and for general web searches.\n",
        "\n",
        "Here are the available tools:\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Thought: (Your reasoning and plan)\n",
        "Action:\n",
        "```json\n",
        "{{\n",
        "  \"action\": \"Your chosen tool\",\n",
        "  \"action_input\": {{\"parameter\": \"value\"}}\n",
        "}}\n",
        "```\n",
        "Observation: (The tool's output)\n",
        "Thought: I have the information. I will now answer the user.\n",
        "Action:\n",
        "```json\n",
        "{{\n",
        "  \"action\": \"Final Answer\",\n",
        "  \"action_input\": \"The answer to the user's question.\"\n",
        "}}\n",
        "```\n",
        "\n",
        "USER INPUT: {input}\n",
        "CHAT HISTORY:\n",
        "{chat_history}\n",
        "\n",
        "Begin!\n",
        "Thought:\n",
        "{agent_scratchpad}\n",
        "\"\"\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0665fbca"
      },
      "source": [
        "### **4.4. The Main Graph (Tying It All Together)**\n",
        "\n",
        "This `RunnableBranch` is the final piece. It takes the *output* of the `router` and selects which agent `AgentExecutor` to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fc9ea3c",
        "outputId": "971cf61d-1e73-4db8-e556-e54aba5648c8"
      },
      "source": [
        "!pip install -U ddgs"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ddgs\n",
            "  Downloading ddgs-9.6.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.2.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
            "Collecting lxml>=6.0.0 (from ddgs)\n",
            "  Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
            "Downloading ddgs-9.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: socksio, lxml, ddgs\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 5.4.0\n",
            "    Uninstalling lxml-5.4.0:\n",
            "      Successfully uninstalled lxml-5.4.0\n",
            "Successfully installed ddgs-9.6.0 lxml-6.0.2 socksio-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b191651"
      },
      "source": [
        "# --- 1. Create all the agent chains ---\n",
        "looker_chain = create_simple_looker_agent()\n",
        "python_chain = create_python_agent_chain()\n",
        "general_chain = create_general_agent_chain()\n",
        "\n",
        "# --- 2. Define the Branch ---\n",
        "# This is the \"Supervisor\" from ARCHITECTURE.md\n",
        "branch = RunnableBranch(\n",
        "    (lambda x: x['route'].destination == \"looker\", looker_chain),\n",
        "    (lambda x: x['route'].destination == \"python_agent\", python_chain),\n",
        "    (lambda x: x['route'].destination == \"general\", general_chain),\n",
        "    general_chain # Default fallback\n",
        ")\n",
        "\n",
        "# --- 3. Define the Full Chain ---\n",
        "# The full chain pipes the input to the router,\n",
        "# then passes the input + route to the branch.\n",
        "\n",
        "full_chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        # Step 1: Call the router. The result is added to the\n",
        "        # input dict under the key 'route'.\n",
        "        route=lambda x: router.invoke(x)\n",
        "    )\n",
        "    | branch # Step 2: Call the selected agent\n",
        ")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "085c2d83"
      },
      "source": [
        "---\n",
        "\n",
        "## **Section 5: Running the Full System**\n",
        "\n",
        "Let's simulate the two-step conversation from our router test.\n",
        "\n",
        "1.  **User:** \"Show me population by state.\"\n",
        "    *   **Router** -> `looker`\n",
        "    *   **Looker Agent** -> Runs query, saves `data.csv`, returns summary and URL.\n",
        "2.  **User:** \"What is the average population from that data?\"\n",
        "    *   **Router** (with history) -> `python_agent`\n",
        "    *   **Python Agent** -> Loads `data.csv`, calculates `.mean()`, returns analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445c80b7",
        "outputId": "3713cefd-742e-4288-df7e-b6797689427f"
      },
      "source": [
        "chat_history = []\n",
        "\n",
        "# --- Conversation Turn 1: Looker Query ---\n",
        "print(\"=\"*40 + \"\\nTURN 1: LOOKER QUERY\\n\" + \"=\"*40)\n",
        "query_1 = \"Show me total population and median income by state, sorted by population desc\"\n",
        "\n",
        "# Run the full chain\n",
        "response_1 = full_chain.invoke({\n",
        "    \"input\": query_1,\n",
        "    \"chat_history\": chat_history\n",
        "})\n",
        "\n",
        "# Update our history\n",
        "chat_history.append(HumanMessage(content=query_1))\n",
        "chat_history.append(AIMessage(content=response_1['output']))\n",
        "\n",
        "print(f\"\\n--- FINAL AGENT 1 OUTPUT ---\\n{response_1['output']}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "TURN 1: LOOKER QUERY\n",
            "========================================\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LookerAgent chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe user is asking for total population and median income by state, sorted by population in descending order. I need to use the `LookerDataQuery` tool to retrieve this information.\n",
            "\n",
            "Here's my plan:\n",
            "1.  **Fields**: I need `state.state_name` for the state, `blockgroup.total_pop` for total population, and `blockgroup.median_income_dim` for median income.\n",
            "2.  **Filters**: No specific filters are mentioned, so I will not apply any.\n",
            "3.  **Sorts**: The user requested sorting by population in descending order, so I'll use `blockgroup.total_pop desc`.\n",
            "4.  **Limit**: The default limit of 500 should be sufficient for all states.\n",
            "5.  **Visualization**: A bar chart or table would be suitable for comparing states. I'll choose a bar chart to easily visualize the population differences, and include median income as a secondary measure. I will use `state.state_name` as the dimension and `blockgroup.total_pop` and `blockgroup.median_income_dim` as measures.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"LookerDataQuery\",\n",
            "  \"action_input\": {\n",
            "    \"fields\": [\n",
            "      \"state.state_name\",\n",
            "      \"blockgroup.total_pop\",\n",
            "      \"blockgroup.median_income_dim\"\n",
            "    ],\n",
            "    \"sorts\": [\n",
            "      \"blockgroup.total_pop desc\"\n",
            "    ],\n",
            "    \"vis_config_string\": \"{\\\"type\\\": \\\"looker_bar\\\", \\\"series_colors\\\": {\\\"blockgroup.total_pop\\\": \\\"#1A73E8\\\", \\\"blockgroup.median_income_dim\\\": \\\"#EA4335\\\"}, \\\"y_axes\\\": [{\\\"label\\\": \\\"Population\\\", \\\"orientation\\\": \\\"left\\\", \\\"series\\\": [{\\\"axis\\\": \\\"blockgroup.total_pop\\\", \\\"id\\\": \\\"blockgroup.total_pop\\\", \\\"name\\\": \\\"Total Pop\\\"}], \\\"show_labels\\\": true, \\\"show_values\\\": true, \\\"value_format\\\": \\\"#,##0\\\"}, {\\\"label\\\": \\\"Median Income\\\", \\\"orientation\\\": \\\"right\\\", \\\"series\\\": [{\\\"axis\\\": \\\"blockgroup.median_income_dim\\\", \\\"id\\\": \\\"blockgroup.median_income_dim\\\", \\\"name\\\": \\\"Median Income Dim\\\"}], \\\"show_labels\\\": true, \\\"show_values\\\": true, \\\"value_format\\\": \\\"$#,##0\\\"}]}\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m--- Running Looker Inline Query --- \n",
            "WriteQuery(model='data_block_acs_bigquery', view='acs_census_data', fields=['state.state_name', 'blockgroup.total_pop', 'blockgroup.median_income_dim'], pivots=None, fill_fields=None, filters={}, filter_expression=None, sorts=['blockgroup.total_pop desc'], limit='500', column_limit=None, total=None, row_total=None, subtotals=None, vis_config={'type': 'looker_bar', 'series_colors': {'blockgroup.total_pop': '#1A73E8', 'blockgroup.median_income_dim': '#EA4335'}, 'y_axes': [{'label': 'Population', 'orientation': 'left', 'series': [{'axis': 'blockgroup.total_pop', 'id': 'blockgroup.total_pop', 'name': 'Total Pop'}], 'show_labels': True, 'show_values': True, 'value_format': '#,##0'}, {'label': 'Median Income', 'orientation': 'right', 'series': [{'axis': 'blockgroup.median_income_dim', 'id': 'blockgroup.median_income_dim', 'name': 'Median Income Dim'}], 'show_labels': True, 'show_values': True, 'value_format': '$#,##0'}]}, filter_config=None, visible_ui_sections=None, dynamic_fields=None, client_id=None, query_timezone=None)\n",
            "--- Data Query Successful ---\n",
            "--- Expanded Embed URL Created: https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=state.state_name%2Cblockgroup.total_pop%2Cblockgroup.median_income_dim&sorts=blockgroup.total_pop+desc&limit=500&vis_config=%7B%22type%22%3A+%22looker_bar%22%2C+%22series_colors%22%3A+%7B%22blockgroup.total_pop%22%3A+%22%231A73E8%22%2C+%22blockgroup.median_income_dim%22%3A+%22%23EA4335%22%7D%2C+%22y_axes%22%3A+%5B%7B%22label%22%3A+%22Population%22%2C+%22orientation%22%3A+%22left%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.total_pop%22%2C+%22id%22%3A+%22blockgroup.total_pop%22%2C+%22name%22%3A+%22Total+Pop%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%23%2C%23%230%22%7D%2C+%7B%22label%22%3A+%22Median+Income%22%2C+%22orientation%22%3A+%22right%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.median_income_dim%22%2C+%22id%22%3A+%22blockgroup.median_income_dim%22%2C+%22name%22%3A+%22Median+Income+Dim%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%24%23%2C%23%230%22%7D%5D%7D&toggle=vis ---\n",
            "--- Data saved to data.csv ---\n",
            "\u001b[36;1m\u001b[1;3m{\"summary\": \"Successfully queried and saved 500 rows to data.csv.\", \"viz_url\": \"https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=state.state_name%2Cblockgroup.total_pop%2Cblockgroup.median_income_dim&sorts=blockgroup.total_pop+desc&limit=500&vis_config=%7B%22type%22%3A+%22looker_bar%22%2C+%22series_colors%22%3A+%7B%22blockgroup.total_pop%22%3A+%22%231A73E8%22%2C+%22blockgroup.median_income_dim%22%3A+%22%23EA4335%22%7D%2C+%22y_axes%22%3A+%5B%7B%22label%22%3A+%22Population%22%2C+%22orientation%22%3A+%22left%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.total_pop%22%2C+%22id%22%3A+%22blockgroup.total_pop%22%2C+%22name%22%3A+%22Total+Pop%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%23%2C%23%230%22%7D%2C+%7B%22label%22%3A+%22Median+Income%22%2C+%22orientation%22%3A+%22right%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.median_income_dim%22%2C+%22id%22%3A+%22blockgroup.median_income_dim%22%2C+%22name%22%3A+%22Median+Income+Dim%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%24%23%2C%23%230%22%7D%5D%7D&toggle=vis\", \"data_preview\": \"[{\\\"state.state_name\\\":\\\"New York\\\",\\\"blockgroup.median_income_dim\\\":null,\\\"blockgroup.total_pop\\\":673895},{\\\"state.state_name\\\":\\\"Texas\\\",\\\"blockgroup.median_income_dim\\\":null,\\\"blockgroup.total_pop\\\":664424},{\\\"state.state_name\\\":\\\"California\\\",\\\"blockgroup.median_income_dim\\\":null,\\\"blockgroup.total_pop\\\":662292},{\\\"state.state_name\\\":\\\"Florida\\\",\\\"blockgroup.median_income_dim\\\":null,\\\"blockgroup.total_pop\\\":321420},{\\\"state.state_name\\\":\\\"Pennsylvania\\\",\\\"blockgroup.median_income_dim\\\":null,\\\"blockgroup.total_pop\\\":260655}]\", \"data_stats\": \"{\\\"blockgroup.median_income_dim\\\":{\\\"count\\\":453.0,\\\"mean\\\":75799.1721854305,\\\"std\\\":39850.4112550972,\\\"min\\\":2499.0,\\\"25%\\\":51720.0,\\\"50%\\\":65000.0,\\\"75%\\\":90000.0,\\\"max\\\":250001.0},\\\"blockgroup.total_pop\\\":{\\\"count\\\":500.0,\\\"mean\\\":29274.542,\\\"std\\\":59813.4746310487,\\\"min\\\":11965.0,\\\"25%\\\":13287.5,\\\"50%\\\":15997.0,\\\"75%\\\":21026.75,\\\"max\\\":673895.0}}\"}\u001b[0m\u001b[32;1m\u001b[1;3mThought: The user asked for total population and median income by state, sorted by population descending. The `LookerDataQuery` tool was used, and the output provides the requested data. However, the `data_preview` shows `blockgroup.median_income_dim` as `null` for the top states, which is unexpected. The `data_stats` for `blockgroup.median_income_dim` shows a count of 453, which means not all 500 rows have a median income value. This suggests that `blockgroup.median_income_dim` might not be the correct field for median income *by state*, or there's an aggregation issue.\n",
            "\n",
            "Looking at the schema, `blockgroup.median_income_dim` is a dimension at the block group level. To get median income *by state*, I should use `state.state_median_income_dim` which is a measure at the state level. The previous query used `blockgroup.median_income_dim` which is a dimension, and when aggregated to the state level, it might not be correctly summing or averaging. I need to re-run the query with the correct median income field for the state level.\n",
            "\n",
            "Let's re-evaluate the fields:\n",
            "1.  `state.state_name`: Correct for state name.\n",
            "2.  `blockgroup.total_pop`: This is a measure, and when grouped by state, it will correctly sum up to the total population for the state.\n",
            "3.  `state.state_median_income_dim`: This is the correct measure for median income at the state level.\n",
            "\n",
            "I will re-run the query with `state.state_median_income_dim` instead of `blockgroup.median_income_dim`. The sorting and visualization configuration will remain similar, adjusting the field name.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"LookerDataQuery\",\n",
            "  \"action_input\": {\n",
            "    \"fields\": [\n",
            "      \"state.state_name\",\n",
            "      \"blockgroup.total_pop\",\n",
            "      \"state.state_median_income_dim\"\n",
            "    ],\n",
            "    \"sorts\": [\n",
            "      \"blockgroup.total_pop desc\"\n",
            "    ],\n",
            "    \"vis_config_string\": \"{\\\"type\\\": \\\"looker_bar\\\", \\\"series_colors\\\": {\\\"blockgroup.total_pop\\\": \\\"#1A73E8\\\", \\\"state.state_median_income_dim\\\": \\\"#EA4335\\\"}, \\\"y_axes\\\": [{\\\"label\\\": \\\"Population\\\", \\\"orientation\\\": \\\"left\\\", \\\"series\\\": [{\\\"axis\\\": \\\"blockgroup.total_pop\\\", \\\"id\\\": \\\"blockgroup.total_pop\\\", \\\"name\\\": \\\"Total Pop\\\"}], \\\"show_labels\\\": true, \\\"show_values\\\": true, \\\"value_format\\\": \\\"#,##0\\\"}, {\\\"label\\\": \\\"Median Income\\\", \\\"orientation\\\": \\\"right\\\", \\\"series\\\": [{\\\"axis\\\": \\\"state.state_median_income_dim\\\", \\\"id\\\": \\\"state.state_median_income_dim\\\", \\\"name\\\": \\\"Median Income\\\"}], \\\"show_labels\\\": true, \\\"show_values\\\": true, \\\"value_format\\\": \\\"$#,##0\\\"}]}\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m--- Running Looker Inline Query --- \n",
            "WriteQuery(model='data_block_acs_bigquery', view='acs_census_data', fields=['state.state_name', 'blockgroup.total_pop', 'state.state_median_income_dim'], pivots=None, fill_fields=None, filters={}, filter_expression=None, sorts=['blockgroup.total_pop desc'], limit='500', column_limit=None, total=None, row_total=None, subtotals=None, vis_config={'type': 'looker_bar', 'series_colors': {'blockgroup.total_pop': '#1A73E8', 'state.state_median_income_dim': '#EA4335'}, 'y_axes': [{'label': 'Population', 'orientation': 'left', 'series': [{'axis': 'blockgroup.total_pop', 'id': 'blockgroup.total_pop', 'name': 'Total Pop'}], 'show_labels': True, 'show_values': True, 'value_format': '#,##0'}, {'label': 'Median Income', 'orientation': 'right', 'series': [{'axis': 'state.state_median_income_dim', 'id': 'state.state_median_income_dim', 'name': 'Median Income'}], 'show_labels': True, 'show_values': True, 'value_format': '$#,##0'}]}, filter_config=None, visible_ui_sections=None, dynamic_fields=None, client_id=None, query_timezone=None)\n",
            "--- Data Query Successful ---\n",
            "--- Expanded Embed URL Created: https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=state.state_name%2Cblockgroup.total_pop%2Cstate.state_median_income_dim&sorts=blockgroup.total_pop+desc&limit=500&vis_config=%7B%22type%22%3A+%22looker_bar%22%2C+%22series_colors%22%3A+%7B%22blockgroup.total_pop%22%3A+%22%231A73E8%22%2C+%22state.state_median_income_dim%22%3A+%22%23EA4335%22%7D%2C+%22y_axes%22%3A+%5B%7B%22label%22%3A+%22Population%22%2C+%22orientation%22%3A+%22left%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.total_pop%22%2C+%22id%22%3A+%22blockgroup.total_pop%22%2C+%22name%22%3A+%22Total+Pop%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%23%2C%23%230%22%7D%2C+%7B%22label%22%3A+%22Median+Income%22%2C+%22orientation%22%3A+%22right%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22state.state_median_income_dim%22%2C+%22id%22%3A+%22state.state_median_income_dim%22%2C+%22name%22%3A+%22Median+Income%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%24%23%2C%23%230%22%7D%5D%7D&toggle=vis ---\n",
            "--- Data saved to data.csv ---\n",
            "\u001b[36;1m\u001b[1;3m{\"summary\": \"Successfully queried and saved 52 rows to data.csv.\", \"viz_url\": \"https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=state.state_name%2Cblockgroup.total_pop%2Cstate.state_median_income_dim&sorts=blockgroup.total_pop+desc&limit=500&vis_config=%7B%22type%22%3A+%22looker_bar%22%2C+%22series_colors%22%3A+%7B%22blockgroup.total_pop%22%3A+%22%231A73E8%22%2C+%22state.state_median_income_dim%22%3A+%22%23EA4335%22%7D%2C+%22y_axes%22%3A+%5B%7B%22label%22%3A+%22Population%22%2C+%22orientation%22%3A+%22left%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.total_pop%22%2C+%22id%22%3A+%22blockgroup.total_pop%22%2C+%22name%22%3A+%22Total+Pop%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%23%2C%23%230%22%7D%2C+%7B%22label%22%3A+%22Median+Income%22%2C+%22orientation%22%3A+%22right%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22state.state_median_income_dim%22%2C+%22id%22%3A+%22state.state_median_income_dim%22%2C+%22name%22%3A+%22Median+Income%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%24%23%2C%23%230%22%7D%5D%7D&toggle=vis\", \"data_preview\": \"[{\\\"state.state_name\\\":\\\"California\\\",\\\"state.state_median_income_dim\\\":71228,\\\"blockgroup.total_pop\\\":39148760},{\\\"state.state_name\\\":\\\"Texas\\\",\\\"state.state_median_income_dim\\\":59570,\\\"blockgroup.total_pop\\\":27885195},{\\\"state.state_name\\\":\\\"Florida\\\",\\\"state.state_median_income_dim\\\":53267,\\\"blockgroup.total_pop\\\":20598139},{\\\"state.state_name\\\":\\\"New York\\\",\\\"state.state_median_income_dim\\\":65323,\\\"blockgroup.total_pop\\\":19618453},{\\\"state.state_name\\\":\\\"Illinois\\\",\\\"state.state_median_income_dim\\\":63575,\\\"blockgroup.total_pop\\\":12821497}]\", \"data_stats\": \"{\\\"state.state_median_income_dim\\\":{\\\"count\\\":52.0,\\\"mean\\\":59842.6923076923,\\\"std\\\":11637.3366917013,\\\"min\\\":20166.0,\\\"25%\\\":52956.5,\\\"50%\\\":58848.0,\\\"75%\\\":68383.25,\\\"max\\\":82604.0},\\\"blockgroup.total_pop\\\":{\\\"count\\\":52.0,\\\"mean\\\":6274807.134615385,\\\"std\\\":7172279.1769014383,\\\"min\\\":581836.0,\\\"25%\\\":1793742.75,\\\"50%\\\":4261073.5,\\\"75%\\\":7033597.75,\\\"max\\\":39148760.0}}\"}\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: ### Summary\n",
            "\n",
            "The query successfully retrieved the total population and median household income for all states in the US, sorted by total population in descending order. The data includes 52 entries, covering all states and the District of Columbia.\n",
            "\n",
            "### Insights\n",
            "\n",
            "California leads in total population with 39,148,760 residents and a median household income of $71,228. Following California are Texas (27,885,195 population, $59,570 median income) and Florida (20,598,139 population, $53,267 median income). The state with the lowest population in this dataset is not explicitly shown in the preview, but the overall minimum population is 581,836. The median household income across all states ranges from a minimum of $20,166 to a maximum of $82,604, with an average median income of approximately $59,843.\n",
            "\n",
            "Here is the link to the visualization: [Looker Viz](https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=state.state_name%2Cblockgroup.total_pop%2Cstate.state_median_income_dim&sorts=blockgroup.total_pop+desc&limit=500&vis_config=%7B%22type%22%3A+%22looker_bar%22%2C+%22series_colors%22%3A+%7B%22blockgroup.total_pop%22%3A+%22%231A73E8%22%2C+%22state.state_median_income_dim%22%3A+%22%23EA4335%22%7D%2C+%22y_axes%22%3A+%5B%7B%22label%22%3A+%22Population%22%2C+%22orientation%22%3A+%22left%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.total_pop%22%2C+%22id%22%3A+%22blockgroup.total_pop%22%2C+%22name%22%3A+%22Total+Pop%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%23%2C%23%230%22%7D%2C+%7B%22label%22%3A+%22Median+Income%22%2C+%22orientation%22%3A+%22right%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22state.state_median_income_dim%22%2C+%22id%22%3A+%22state.state_median_income_dim%22%2C+%22name%22%3A+%22Median+Income%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%24%23%2C%23%230%22%7D%5D%7D&toggle=vis)\n",
            "%2C%23%230%22%7D%5D%7D&toggle=vis)\n",
            "\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mThe previous attempt to provide a final answer failed due to an output parsing error. I need to ensure the final answer is correctly formatted in MARKDOWN with the specified headings and includes the `viz_url`.\n",
            "\n",
            "I have successfully retrieved the data for total population and median income by state, sorted by population descending. The `data_preview` and `data_stats` from the last `LookerDataQuery` call contain the necessary information to construct the final answer.\n",
            "\n",
            "Here's the plan for the final answer:\n",
            "1.  **Summary**: Describe the data retrieved (total population and median income for all states, sorted by population).\n",
            "2.  **Insights**: Use the `data_preview` to highlight the top states by population and their median incomes. Use `data_stats` to mention the range and average of median income and population.\n",
            "3.  **Viz URL**: Include the provided `viz_url`.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"### Summary\\n\\nThe query successfully retrieved the total population and median household income for all 50 US states and the District of Columbia, sorted by total population in descending order. The dataset contains 52 entries, providing a comprehensive overview of demographic and economic indicators across the nation.\\n\\n### Insights\\n\\nCalifornia leads the nation with the highest total population of 39,148,760, reporting a median household income of $71,228. It is followed by Texas, with a population of 27,885,195 and a median income of $59,570, and Florida, with 20,598,139 residents and a median income of $53,267. The median household income across all states ranges from a minimum of $20,166 to a maximum of $82,604, with an average median income of approximately $59,843. The total population across these geographies varies significantly, from a minimum of 581,836 to the maximum observed in California.\\n\\nHere is the link to the visualization: [Looker Viz](https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=state.state_name%2Cblockgroup.total_pop%2Cstate.state_median_income_dim&sorts=blockgroup.total_pop+desc&limit=500&vis_config=%7B%22type%22%3A+%22looker_bar%22%2C+%22series_colors%22%3A+%7B%22blockgroup.total_pop%22%3A+%22%231A73E8%22%2C+%22state.state_median_income_dim%22%3A+%22%23EA4335%22%7D%2C+%22y_axes%22%3A+%5B%7B%22label%22%3A+%22Population%22%2C+%22orientation%22%3A+%22left%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.total_pop%22%2C+%22id%22%3A+%22blockgroup.total_pop%22%2C+%22name%22%3A+%22Total+Pop%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%23%2C%23%230%22%7D%2C+%7B%22label%22%3A+%22Median+Income%22%2C+%22orientation%22%3A+%22right%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22state.state_median_income_dim%22%2C+%22id%22%3A+%22state.state_median_income_dim%22%2C+%22name%22%3A+%22Median+Income%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%24%23%2C%23%230%22%7D%5D%7D&toggle=vis)\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "--- FINAL AGENT 1 OUTPUT ---\n",
            "### Summary\n",
            "\n",
            "The query successfully retrieved the total population and median household income for all 50 US states and the District of Columbia, sorted by total population in descending order. The dataset contains 52 entries, providing a comprehensive overview of demographic and economic indicators across the nation.\n",
            "\n",
            "### Insights\n",
            "\n",
            "California leads the nation with the highest total population of 39,148,760, reporting a median household income of $71,228. It is followed by Texas, with a population of 27,885,195 and a median income of $59,570, and Florida, with 20,598,139 residents and a median income of $53,267. The median household income across all states ranges from a minimum of $20,166 to a maximum of $82,604, with an average median income of approximately $59,843. The total population across these geographies varies significantly, from a minimum of 581,836 to the maximum observed in California.\n",
            "\n",
            "Here is the link to the visualization: [Looker Viz](https://igmprinting.cloud.looker.com/embed/explore/data_block_acs_bigquery/acs_census_data?fields=state.state_name%2Cblockgroup.total_pop%2Cstate.state_median_income_dim&sorts=blockgroup.total_pop+desc&limit=500&vis_config=%7B%22type%22%3A+%22looker_bar%22%2C+%22series_colors%22%3A+%7B%22blockgroup.total_pop%22%3A+%22%231A73E8%22%2C+%22state.state_median_income_dim%22%3A+%22%23EA4335%22%7D%2C+%22y_axes%22%3A+%5B%7B%22label%22%3A+%22Population%22%2C+%22orientation%22%3A+%22left%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22blockgroup.total_pop%22%2C+%22id%22%3A+%22blockgroup.total_pop%22%2C+%22name%22%3A+%22Total+Pop%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%23%2C%23%230%22%7D%2C+%7B%22label%22%3A+%22Median+Income%22%2C+%22orientation%22%3A+%22right%22%2C+%22series%22%3A+%5B%7B%22axis%22%3A+%22state.state_median_income_dim%22%2C+%22id%22%3A+%22state.state_median_income_dim%22%2C+%22name%22%3A+%22Median+Income%22%7D%5D%2C+%22show_labels%22%3A+true%2C+%22show_values%22%3A+true%2C+%22value_format%22%3A+%22%24%23%2C%23%230%22%7D%5D%7D&toggle=vis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb510912",
        "outputId": "3b70b9f2-11bd-4261-e9da-b51d7720525a"
      },
      "source": [
        "# --- Conversation Turn 2: Python Agent Query ---\n",
        "print(\"=\"*40 + \"\\nTURN 2: PYTHON ANALYSIS\\n\" + \"=\"*40)\n",
        "query_2 = \"What is the average median income and max population from that data?\"\n",
        "\n",
        "# Run the full chain\n",
        "response_2 = full_chain.invoke({\n",
        "    \"input\": query_2,\n",
        "    \"chat_history\": chat_history\n",
        "})\n",
        "\n",
        "# Update our history\n",
        "chat_history.append(HumanMessage(content=query_2))\n",
        "chat_history.append(AIMessage(content=response_2['output']))\n",
        "\n",
        "print(f\"\\n--- FINAL AGENT 2 OUTPUT ---\\n{response_2['output']}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "TURN 2: PYTHON ANALYSIS\n",
            "========================================\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new PythonAgent chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought:\n",
            "The user wants to know the average median income and the maximum population from the dataset.\n",
            "\n",
            "My plan is:\n",
            "1.  Load the `data.csv` file into a pandas DataFrame named `df`.\n",
            "2.  Print the column names to identify the correct columns for population and median income.\n",
            "3.  Calculate the mean of the median income column.\n",
            "4.  Calculate the maximum value of the population column.\n",
            "5.  Combine these two results into a final, conversational answer.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Python_REPL\",\n",
            "  \"action_input\": \"import pandas as pd\\ndf = pd.read_csv('data.csv')\\nprint(df.columns)\"\n",
            "}\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3mIndex(['state.state_name', 'state.state_median_income_dim',\n",
            "       'blockgroup.total_pop'],\n",
            "      dtype='object')\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mThe user wants to find the average median income and the maximum population.\n",
            "From the previous step, I have the column names:\n",
            "- `'state.state_median_income_dim'` for median income.\n",
            "- `'blockgroup.total_pop'` for population.\n",
            "\n",
            "Now I will calculate the average of `'state.state_median_income_dim'` and the maximum of `'blockgroup.total_pop'`. I can do this in a single step to be more efficient.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Python_REPL\",\n",
            "  \"action_input\": \"avg_income = df['state.state_median_income_dim'].mean()\\nmax_pop = df['blockgroup.total_pop'].max()\\nprint(f'Average Median Income: {avg_income}')\\nprint(f'Maximum Population: {max_pop}')\"\n",
            "}\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3mAverage Median Income: 59842.692307692305\n",
            "Maximum Population: 39148760\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: I have analyzed the data and found the values you were looking for.\n",
            "\n",
            "Based on the dataset, the average median income across all the states listed is approximately **$59,842.69**. The highest population recorded for a single state in this data is **39,148,760**.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: I have analyzed the data and found the values you were looking for.\n",
            "\n",
            "Based on the dataset, the average median income across all the states listed is approximately **$59,842.69**. The highest population recorded for a single state in this data is **39,148,760**.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: I have analyzed the data and found the values you were looking for.\n",
            "\n",
            "Based on the dataset, the average median income across all the states listed is approximately **$59,842.69**. The highest population recorded for a single state in this data is **39,148,760**.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: I have analyzed the data and found the values you were looking for.\n",
            "\n",
            "Based on the dataset, the average median income across all the states listed is approximately **$59,842.69**. The highest population recorded for a single state in this data is **39,148,760**.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: I have analyzed the data and found the values you were looking for.\n",
            "\n",
            "Based on the dataset, the average median income across all the states listed is approximately **$59,842.69**. The highest population recorded for a single state in this data is **39,148,760**.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: I have analyzed the data and found the values you were looking for.\n",
            "\n",
            "Based on the dataset, the average median income across all the states listed is approximately **$59,842.69**. The highest population recorded for a single state in this data is **39,148,760**.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "--- FINAL AGENT 2 OUTPUT ---\n",
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c780bd3",
        "outputId": "3e947152-ff4a-4e20-8764-2b7eb7051774"
      },
      "source": [
        "# --- Conversation Turn 3: General Query ---\n",
        "print(\"=\"*40 + \"\\nTURN 3: GENERAL KNOWLEDGE\\n\" + \"=\"*40)\n",
        "query_3 = \"What is the weather in New York?\"\n",
        "\n",
        "# Run the full chain\n",
        "response_3 = full_chain.invoke({\n",
        "    \"input\": query_3,\n",
        "    \"chat_history\": chat_history\n",
        "})\n",
        "\n",
        "# Update our history\n",
        "chat_history.append(HumanMessage(content=query_3))\n",
        "chat_history.append(AIMessage(content=response_3['output']))\n",
        "\n",
        "print(f\"\\n--- FINAL AGENT 3 OUTPUT ---\\n{response_3['output']}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "TURN 3: GENERAL KNOWLEDGE\n",
            "========================================\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new GeneralAgent chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The user is asking for the weather in New York. I do not have a specific weather tool, but I can use the `DuckDuckGoSearchRun` tool to get this information from the web. I will search for \"weather in New York\" to get the current conditions.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"DuckDuckGoSearchRun\",\n",
            "  \"action_input\": {\n",
            "    \"query\": \"weather in New York\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m2 weeks ago - In the Holdridge life zones system, having a mean annual biotemperature above 53.6 °F (12 °C) and mean annual precipitation above 39.4 inches (1,000 mm), New York City features a warm temperate moist forest climate . By the Trewartha classification, the city is defined as having a Temperate ... New York - Weather warnings issued. 14-day forecast.Observations - New York Downtown Manhattan Heli. Observed at 14:00, Saturday 6 September. Current weather in New York and forecast for today, tomorrow, and next 14 days. Use Current Location. Recent. New York .Expect showery weather late tonight through Thursday morning. New York Weather Radar. New York , current weather : clear. Light rain will start at night, around 3:00. Air temperature +21°, feels like +17°. Wind speed 7.2 Meters per second, north-easterly.\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: It looks like the weather in New York is currently clear. The temperature is around 70°F, but it feels more like 63°F with a north-easterly wind.\n",
            "\n",
            "You can expect some light rain to start late tonight, around 3:00 AM, with showers continuing through Thursday morning.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mThought: The user is asking for the weather in New York. I do not have a specific weather tool, but I can use the `DuckDuckGoSearchRun` tool to get this information from the web. I will search for \"weather in New York\" to get the current conditions.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"DuckDuckGoSearchRun\",\n",
            "  \"action_input\": {\n",
            "    \"query\": \"weather in New York\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m2 weeks ago - In the Holdridge life zones system, having a mean annual biotemperature above 53.6 °F (12 °C) and mean annual precipitation above 39.4 inches (1,000 mm), New York City features a warm temperate moist forest climate . By the Trewartha classification, the city is defined as having a Temperate ... 1 day ago - Stay informed on local weather updates for New York City, NY. Discover the weather conditions in New York City & see if there is a chance of rain, snow, or sunshine. Plan your activities, travel, or work with confidence by checking out our detailed hourly forecast for New York City. 1 week ago - Manhattan is looking at showers and thunderstorms mainly after 2pm today, with the possibility of some storms being severe and an expected high near 87 degrees . The chance of precipitation stands at a formidable 80%, and new rainfall could accumulate between a half and three quarters of an inch. July 7, 2025 - News10NBC First Alert Weather Tracking Your Summer Wondering what summer has in store for our region? Our First Alert Weather Team is tracking your summer from heat wave predictions to tornado safety. Check it out: Downloading the First Alert Weather app For the most up-to-date forecasts specific ... 2 days ago - SYRACUSE, N.Y. (WSYR-TV) — We have officially reached a warm weather milestone of sorts in Syracuse: five years without a record low. The last time we had a record low temperature in the Salt City was all the way back on September 21, 2020. The low that day was 34 degrees. In the time since […]\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: I can certainly help with that!\n",
            "\n",
            "Based on the latest forecast, it looks like New York City, specifically Manhattan, is expecting showers and thunderstorms this afternoon, mainly after 2 p.m. Some of the storms could be severe.\n",
            "\n",
            "The high temperature for today will be around 87 degrees, and there's an 80% chance of rain, which could bring between half an inch and three-quarters of an inch of precipitation.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mThought: The user is asking for the weather in New York. I don't have a dedicated weather tool, but I can use the `DuckDuckGoSearchRun` tool to find the current weather forecast online. I will search for \"weather in New York\" to get the information.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"DuckDuckGoSearchRun\",\n",
            "  \"action_input\": {\n",
            "    \"query\": \"weather in New York\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m2 weeks ago - In the Holdridge life zones system, having a mean annual biotemperature above 53.6 °F (12 °C) and mean annual precipitation above 39.4 inches (1,000 mm), New York City features a warm temperate moist forest climate . By the Trewartha classification, the city is defined as having a Temperate ... 1 day ago - Stay informed on local weather updates for New York City, NY. Discover the weather conditions in New York City & see if there is a chance of rain, snow, or sunshine. Plan your activities, travel, or work with confidence by checking out our detailed hourly forecast for New York City. 1 week ago - Manhattan is looking at showers and thunderstorms mainly after 2pm today, with the possibility of some storms being severe and an expected high near 87 degrees . The chance of precipitation stands at a formidable 80%, and new rainfall could accumulate between a half and three quarters of an inch. July 7, 2025 - News10NBC First Alert Weather Tracking Your Summer Wondering what summer has in store for our region? Our First Alert Weather Team is tracking your summer from heat wave predictions to tornado safety. Check it out: Downloading the First Alert Weather app For the most up-to-date forecasts specific ... 2 days ago - SYRACUSE, N.Y. (WSYR-TV) — We have officially reached a warm weather milestone of sorts in Syracuse: five years without a record low. The last time we had a record low temperature in the Salt City was all the way back on September 21, 2020. The low that day was 34 degrees. In the time since […]\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: I can certainly help you with that!\n",
            "\n",
            "Based on a recent forecast for Manhattan, it looks like you can expect showers and thunderstorms, mainly after 2 p.m. today. There's a possibility that some of these storms could be severe.\n",
            "\n",
            "The high temperature is expected to be around 87 degrees, and there's a high chance of rain (80%), with rainfall possibly accumulating between half an inch and three-quarters of an inch.\n",
            "\n",
            "For the most up-to-the-minute information, it's always a good idea to check a local weather source\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mThought: The user is asking for the weather in New York. I don't have a dedicated weather tool, but I can use the `DuckDuckGoSearchRun` tool to find the current weather forecast online. I will search for \"weather in New York\" to get the information.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"DuckDuckGoSearchRun\",\n",
            "  \"action_input\": {\n",
            "    \"query\": \"weather in New York\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m2 weeks ago - In the Holdridge life zones system, having a mean annual biotemperature above 53.6 °F (12 °C) and mean annual precipitation above 39.4 inches (1,000 mm), New York City features a warm temperate moist forest climate . By the Trewartha classification, the city is defined as having a Temperate ... 1 day ago - Stay informed on local weather updates for New York City, NY. Discover the weather conditions in New York City & see if there is a chance of rain, snow, or sunshine. Plan your activities, travel, or work with confidence by checking out our detailed hourly forecast for New York City. Be prepared with the most accurate 10-day forecast for New York , NY with highs, lows, chance of precipitation from The Weather Channel and Weather.com New York , NY Weather Forecast, with current conditions, wind, air quality, and what to expect for the next 3 days. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the New York City area.\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: I can't give you the real-time weather, but I can find the latest forecast for you!\n",
            "\n",
            "Based on recent reports, it looks like New York City has a chance of showers and thunderstorms, with a high temperature around 87 degrees.\n",
            "\n",
            "For the most accurate, up-to-the-minute conditions, I'd recommend checking a local weather source like The Weather Channel or a local news outlet.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "--- FINAL AGENT 3 OUTPUT ---\n",
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07f3c79b"
      },
      "source": [
        "## **Conclusion**\n",
        "\n",
        "This notebook has demonstrated the core, frontend-agnostic logic of the Looker-Gemini chatbot. We successfully:\n",
        "1.  **Fetched Metadata** from a Looker Explore to ground the LLM.\n",
        "2.  **Built a `looker_data_tool`** that queries Looker, generates an embed URL, and caches the data to `data.csv`.\n",
        "3.  **Built a `PythonREPLTool`** that can securely analyze the cached `data.csv`.\n",
        "4.  **Created a `Router`** to classify user intent.\n",
        "5.  **Assembled a Multi-Agent System** using a `RunnableBranch` that directs traffic to a specialized **Looker Agent**, **Python Agent**, or **General Agent**, creating a seamless conversational data experience."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}